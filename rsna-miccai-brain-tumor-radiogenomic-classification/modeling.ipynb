{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55790c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "styles = \"\"\"\n",
    "<style>\n",
    ".section-heading { \n",
    "  background:#008080; \n",
    "  border:0; \n",
    "  color:white; \n",
    "  text-align:center; \n",
    "  height: 100px; \n",
    "  display: flex;  \n",
    "  justify-content: center;\n",
    "  align-items: center;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6c0c3",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<h2 class=\"section-heading\">\n",
    "    <span>\n",
    "        Quick Navigation\n",
    "    </span>\n",
    "</h2>\n",
    "\n",
    "* [Overview](#overview)\n",
    "* [Data Visualization](#data_viz)\n",
    "    \n",
    "\n",
    "* [Competition Metric](#10)\n",
    "* [Sample Submission](#20)\n",
    "    \n",
    "\n",
    "* [Modeling](#modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3080a",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "\n",
    "<h2 class=\"section-heading\">\n",
    "    <span>\n",
    "      Overview\n",
    "    </span>\n",
    "</h2>\n",
    "\n",
    "* TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ed4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "from utils import competition_name, path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (InputLayer, Conv3D, MaxPool3D, Dropout, Flatten, \n",
    "                                     BatchNormalization, GlobalAveragePooling3D, Dense)\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d07bb56",
   "metadata": {},
   "source": [
    "<a id=\"extraction\"></a>\n",
    "\n",
    "<h2 class=\"section-heading\">\n",
    "    <span>\n",
    "      Extraction\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = (path / 'train')\n",
    "labels = (pd.read_csv(path / 'train_labels.csv', dtype={'BraTS21ID': str})\n",
    "          .set_index('BraTS21ID'))\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ef228",
   "metadata": {},
   "source": [
    "**NOTE**: There are some unexpected issues with the following three cases in the training dataset, participants can exclude the cases during training: [00109, 00123, 00709]. We have checked and confirmed that the testing dataset is free from such issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93431ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusions = ['00109', '00123', '00709']\n",
    "mask = labels.index.isin(exclusions)\n",
    "labels.loc[mask, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Label Count Pre-Removal:  {len(labels):4d}\")\n",
    "labels = labels.loc[~mask, ]\n",
    "print(f\"Label Count Post-Removal: {len(labels):4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d67c4a8",
   "metadata": {},
   "source": [
    "Let's split our training and test set first using just the indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238296c",
   "metadata": {},
   "source": [
    "`DataGenerator` inspiration from [this blog](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly) from Stanford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRILoader:\n",
    "    MRI_TYPES = (\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\")\n",
    "    ROT_CHOICES = [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
    "    PATH = path\n",
    "    \n",
    "    def __init__(self, mri_type, num_images=64, image_size=256):\n",
    "        self.mri_type = mri_type\n",
    "        self.image_size = image_size\n",
    "        self.num_images = num_images\n",
    "        \n",
    "    def create_path(self, patient_id, image_num, split='train'):\n",
    "        return self.PATH / split / patient_id / self.mri_type / f'Image-{image_num}.dcm'\n",
    "    \n",
    "    def load_dicom_image(self, path, voi_lut=True, rotation=None):\n",
    "        dicom = pydicom.read_file(path)\n",
    "        \n",
    "        image = pydicom.read_file(path).pixel_array\n",
    "        if voi_lut:\n",
    "            image = pydicom.pixel_data_handlers.util.apply_voi_lut(image, dicom)\n",
    "\n",
    "        if rotation is not None:\n",
    "            image = cv2.rotate(image, rotation)\n",
    "\n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def load_dicom_images_3d(self, patient_id, split=\"train\", rotation=None):\n",
    "\n",
    "        filepath = path / split / patient_id / self.mri_type\n",
    "        dicom_filenames = sorted(filepath.glob(\"*.dcm\"), key=lambda x: x.stem.split('-')[-1])\n",
    "        s = self.images_selector(len(dicom_filenames))\n",
    "        \n",
    "        scan_images = np.stack([self.load_dicom_image(f, rotation=rotation) for f in dicom_filenames[s]]).T\n",
    "        \n",
    "        if scan_images.shape[-1] < self.num_images:\n",
    "            cnt_of_images_to_add = self.num_images - scan_images.shape[-1]\n",
    "            n_zero = np.zeros((self.image_size, self.image_size, cnt_of_images_to_add))\n",
    "            scan_images = np.concatenate((scan_images,  n_zero), axis = -1)\n",
    "\n",
    "        if np.min(scan_images) < np.max(scan_images):\n",
    "            scan_images = scan_images - np.min(scan_images)\n",
    "            scan_images = scan_images / np.max(scan_images)\n",
    "\n",
    "        return np.expand_dims(scan_images, -1)\n",
    "    \n",
    "    def images_selector(self, num_files):\n",
    "        middle = num_files // 2\n",
    "        p1 = max(0, middle - self.num_images // 2)\n",
    "        p2 = min(num_files, middle + self.num_images // 2)\n",
    "        return slice(p1, p2)\n",
    "    \n",
    "\n",
    "loaders = {mri_type: MRILoader(mri_type) for mri_type in MRILoader.MRI_TYPES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b419b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldr = MRILoader('FLAIR')\n",
    "dicom_path = ldr.create_path('00675', 90)\n",
    "ldr.load_dicom_image(dicom_path)\n",
    "image = ldr.load_dicom_images_3d(\"00100\")\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb5b02",
   "metadata": {},
   "source": [
    "<a id=\"data_generator\"></a>\n",
    "\n",
    "<h2 class=\"section-heading\">\n",
    "    <span>\n",
    "      Data Generator\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb2f8a",
   "metadata": {},
   "source": [
    "`DataGenerator` inspiration from [this blog](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly) from Stanford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e18aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, mri_type, brats21ids, labels, batch_size=4, dim=(128, 128, 64), n_channels=1, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.brats21ids = brats21ids\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.mri_type = mri_type\n",
    "        self.loader = MRILoader(mri_type, image_size=dim[0])\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the number of batches per epoch\n",
    "        Believe this is used to define the iterator length to pass for indexes in __getitem__\n",
    "        \"\"\"\n",
    "        return len(self.brats21ids) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generates one batch of data\n",
    "        \"\"\"\n",
    "        start, stop = index * self.batch_size, (index + 1) * self.batch_size\n",
    "        indexes = self.indexes[start:stop]\n",
    "        \n",
    "        # Find list of IDs\n",
    "        batch_brats21ids = (self.brats21ids[i] for i in indexes)\n",
    "        \n",
    "        # Generate data        \n",
    "        X, y = self.__generate_data(batch_brats21ids)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.brats21ids))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_data(self, batch_brats21ids):\n",
    "        \"\"\"\n",
    "        Produces batches of data. \n",
    "        Takes as argument the list of IDs of the target batch\n",
    "        \"\"\"\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, 1), dtype=int)\n",
    "        \n",
    "        for i, brats21id in enumerate(batch_brats21ids):\n",
    "            X[i,] = self.loader.load_dicom_images_3d(brats21id)\n",
    "            y[i] = self.labels.loc[brats21id, 'MGMT_value']\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdca628",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats21ids_train, brats21ids_valid = train_test_split(labels.index, test_size=0.18, random_state=11)\n",
    "print(f'{\"Training Size:\":20}{len(brats21ids_train): >6d}\\n'\n",
    "      f'{\"Validation Size:\":20}{len(brats21ids_valid): >6d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542b51c",
   "metadata": {},
   "source": [
    "<a id=\"data_viz\"></a>\n",
    "\n",
    "<h2 class=\"section-heading\">\n",
    "    <span>\n",
    "    Data Visualization\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952734c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(11)\n",
    "\n",
    "\n",
    "brats21id = labels.sample(1).index[0]\n",
    "patient_path = path / 'train' / brats21id\n",
    "\n",
    "brats21id = patient_path.stem\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "\n",
    "for ax, mri_type in zip(axes, MRILoader.MRI_TYPES):\n",
    "    ldr = loaders[mri_type]\n",
    "    mri_type_path = patient_path / mri_type\n",
    "    image_paths = sorted(mri_type_path.glob('*'), key=lambda x: x.stem.split('-')[-1])\n",
    "\n",
    "    image_path = image_paths[len(image_paths) // 2]\n",
    "    data = ldr.load_dicom_image(image_path)\n",
    "\n",
    "    outcome = labels.loc[brats21id, 'MGMT_value']\n",
    "\n",
    "    ax.imshow(data, cmap=\"gray\")\n",
    "    ax.set_title(mri_type, fontsize=16)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(f'Patient #{brats21id}: {outcome}', size=24)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_labels = (labels.MGMT_value.value_counts(normalize=True)\n",
    "              .sort_index()\n",
    "              .map('{:0.1%}'.format)\n",
    "              .to_list())\n",
    "training_size = labels.shape[0]\n",
    "\n",
    "ax = sns.countplot(data=labels, x='MGMT_value')\n",
    "sns.despine(right=False)\n",
    "\n",
    "ax.set_title('MGMT Distribution ({:0.0f} records)'.format(training_size), size=16)\n",
    "ax.set_xticklabels(('Not Present', 'Present'))\n",
    "ax.set(xlabel='', ylabel='')\n",
    "\n",
    "# add bar labels\n",
    "for p, label in zip(ax.patches, bar_labels):\n",
    "    ax.annotate(label, (p.get_x()+0.375, p.get_height()+0.15))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ce81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_dirs = train_path.glob('*')\n",
    "\n",
    "scan_sizes = dict()\n",
    "\n",
    "records = dict()\n",
    "\n",
    "for patient_dir in patient_dirs:\n",
    "    record = dict()\n",
    "    for mri_type in MRILoader.MRI_TYPES:\n",
    "        images_path = patient_dir / mri_type\n",
    "        record[mri_type] = len(list(images_path.glob('*.dcm')))\n",
    "    \n",
    "    records[patient_dir.name] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri_image_counts = pd.DataFrame(records).T\n",
    "\n",
    "ax = sns.boxplot(data=df_mri_image_counts)\n",
    "ax.set_title('Distribution of MRI Scan Image Counts')\n",
    "\n",
    "df_mri_image_counts.describe().applymap('{:,.0f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri_image_counts.loc[df_mri_image_counts.FLAIR < 60, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cbf604",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_mri_image_counts, x='FLAIR')\n",
    "plt.show()\n",
    "\n",
    "df_mri_image_counts.loc[:, 'FLAIR'].value_counts().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a78d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mri_image_counts.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a7fa5",
   "metadata": {},
   "source": [
    "**NOTE**: There are some unexpected issues with the following three cases in the training dataset, participants can exclude the cases during training: [00109, 00123, 00709]. We have checked and confirmed that the testing dataset is free from such issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f07ff",
   "metadata": {},
   "source": [
    "<a id=\"modeling\"></a>\n",
    "\n",
    "<h2 class=\"section-heading\">\n",
    "    <span>\n",
    "        Modeling\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(image_size):\n",
    "    inputs = keras.Input((image_size, image_size, 64, 1))\n",
    "        \n",
    "    X = Conv3D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    X = MaxPool3D(pool_size=2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    X = Conv3D(128, kernel_size=3, activation='relu')(X)\n",
    "    X = MaxPool3D(pool_size=2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    X = Conv3D(256, kernel_size=3, activation='relu')(X)\n",
    "    X = MaxPool3D(pool_size=2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "                \n",
    "    X = Conv3D(512, kernel_size=3, activation='relu')(X)\n",
    "    X = MaxPool3D(pool_size=2)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "    X = GlobalAveragePooling3D()(X)\n",
    "    X = Dense(units=1024, activation='relu')(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    outputs = Dense(units=1, activation='sigmoid')(X) \n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2cd7a",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c9b33",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f95477",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_image_classification.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"auc\", patience=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bde66f",
   "metadata": {},
   "source": [
    "#### Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fa58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_type = 'FLAIR'\n",
    "sizes = dict(\n",
    "    batch_size = 2,\n",
    "    dim = (128, 128, 64)\n",
    ")\n",
    "training_set_generator = DataGenerator(mri_type, brats21ids_train, labels, **sizes)\n",
    "validation_set_generator = DataGenerator(mri_type, brats21ids_valid, labels, **sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19c02e",
   "metadata": {},
   "source": [
    "#### Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd5c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_set_generator,\n",
    "          validation_data=validation_set_generator,\n",
    "          # use_multiprocessing=True, # can't use these as there is a multiprocessing ipython issue :\\\n",
    "          # workers=6,\n",
    "          epochs=5, \n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          callbacks=[early_stopping_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54204a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid_probs = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [pd.Series(brats21id_idx_valid), pd.Series(yhat_valid)]\n",
    "results = (pd.concat(frames, axis=1, keys=['brats21id', 'MGMT_value_pred'])\n",
    "           .groupby('brats21id', as_index=False).mean()\n",
    "           .rename(columns={'MGMT_value': 'MGMT_value_preds'})\n",
    "           .merge(training_labels, left_on='brats21id', right_index=True, how='left')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde7aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(results.MGMT_value, results.MGMT_value_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
